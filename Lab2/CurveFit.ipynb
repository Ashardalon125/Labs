{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve fitting in python\n",
    "## Computational Physics - Phy 325\n",
    "An introduction to various curve fitting routines useful for physics work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define `x` as a linear space with 100 points that range from 0 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y` is mock data that we create by linear function with a slope of 1.45. We also add a small amount of random data to simulate noise as if this were a measured quantity. Notice the `np.random.random` function takes a size argument and returns an array of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 1.45 * x + 5*np.random.random(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is pretty clearly linear, but we can fit a line to determine the slope. A 1st order polynomial is a line, so we use `polyfit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# execute the fit on the data; a 1-dim fit (line)\n",
    "fit, cov = np.polyfit(x, y, 1,cov=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit is stored in a variable called `fit` which has two elements. The covariance matrix diagonals are the variance in the fit parameters. Use these to calculate the standard deviation in the fit parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = fit[0]\n",
    "b = fit[1]\n",
    "print(\"a =\",a,\" b =\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da = np.sqrt(cov[0,0])\n",
    "db = np.sqrt(cov[1,1])\n",
    "print(\"da = {:.3f}   db = {:.3f}\".format(da,db))  #note this method to format printing.  More on this soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the data and the fits with their full range of values (a±da and b±db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,\".\")\n",
    "plt.plot(x,(a+da)*x + b,\"r\")\n",
    "plt.plot(x,(a-da)*x + b,\"r\")\n",
    "plt.plot(x,a*x + b + db,\"b\")\n",
    "plt.plot(x,a*x + b - db,\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using linear regression builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,100)\n",
    "y = 0.01 * x + 2 + 2*np.random.random(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,\".\")\n",
    "plt.ylim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regresfit = linregress(x,y)\n",
    "regresfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General function fitting\n",
    "### For more than just polynomials\n",
    "> \"When choosing a fit, Polynomial is almost always the wrong answer\" - Ancient Physics Wisdom\n",
    "\n",
    "Often there is a better model that describes the data. In most cases this is a known function; something like a power law or an exponential. In these cases, there are two options:\n",
    "1. Convert the variables so that a plot will be linear (i.e. plot the `log` of your data, or the square root, or the square etc.). This is highly effective because a linear fit can often be more accurate than a fit of another function.\n",
    "2. Perform a nonlinear fit to the function that models your data. We'll illustrate this below and show how even a \"decent\" fit gives several % error.\n",
    "\n",
    "First, we import the functions that do nonlinear fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define a function that we expect models our system. In this case, exponential decay with an offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pure (i.e. exact) set of data with some parameters, and then simulate some data of the same system (by adding random noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = func(x, 2.5, 0.6, 0.5)\n",
    "ydata = y * (1.0 + 0.1*np.random.normal(size=len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,ydata,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now carry out the fit. `curve_fit` returns two outputs, the fit parameters, and the covariance matrix. We won't use the covariance matrix yet, but it's good practice to save it into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters, covariance = curve_fit(func, x, ydata)\n",
    "parameters  #the fit results for a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the parameters are a reasonable match to the pure function we created above. Next, we want to create a \"best fit\" data set but using the parameters in the model function `func`. The \"splat\" operator is handy for this, it unpacks the `parameters` array into function arguments `a`, `b`, and `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yfit = func(x, *parameters) \n",
    "# the splat operator unpacks an array into function arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,ydata,\".\")\n",
    "plt.plot(x,yfit)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good as far as fits go. Let's check out the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,((yfit-y)/y)*100)\n",
    "plt.title(\"Fit error %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further illustrate the variation in this fit, repeat all the cells (to get new random noise in the data) and you'll see the fit changes. Sometimes, the error is as large as 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling by rescaling data\n",
    "### The \"fit a line to anything\" approach\n",
    "> \"With a small enough data set, you can always fit it to a line\" - More Ancient Wisdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ylog = np.log(ydata)\n",
    "plt.plot(x,ylog,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very linear... why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# because we have a y offset of 0.5. Taking that out gives a linear result.\n",
    "ylog = np.log(np.abs(ydata - 0.5))\n",
    "plt.plot(x,ylog,\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitlog = np.polyfit(x, ylog, 1,full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flog = np.poly1d(fitlog[0])\n",
    "plt.plot(x,ylog)\n",
    "plt.plot(x,flog(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to finally back out the exponential from the linear fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ylogfit = np.exp(flog(x))\n",
    "plt.plot(x,ylogfit + 0.5)\n",
    "plt.plot(x,ydata,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tail is good but the beginning is not. We actually want to emphasize that region (becuase it is where our data is more accurate (larger numbers). Also, we can't know the shift is 0.5 so we have to extract it from the data. We can do this by averaging the last 20 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yshift = np.average(ydata[-20:])\n",
    "yshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also, run the fit on the early part of the data to emphasize those points.\n",
    "ylog = (np.log(ydata[1:25] - yshift))\n",
    "fitlog = np.polyfit(x[1:25], ylog, 1,full=True)  \n",
    "flog = np.poly1d(fitlog[0])\n",
    "plt.plot(x[1:25],ylog)\n",
    "plt.plot(x[1:25],flog(x[1:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ylogfit = np.exp(flog(x))\n",
    "plt.plot(x,ylogfit+yshift)\n",
    "plt.plot(x,ydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x,((ylogfit+yshift-y)/y)*100)\n",
    "plt.title(\"Fit error %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The builtin fit (scipy.optimize.curve_fit) generally does better, it's pretty well designed for fitting (as you would hope)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
